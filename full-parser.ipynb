{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import DictionaryParser\n",
    "from DictionaryParser import DictionaryParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sorted_data.json', 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>expectingMothers</th>\n",
       "      <th>lineContainingQuery</th>\n",
       "      <th>concatenatedValues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-16</td>\n",
       "      <td>Chara Stevenson, Beth Pierce, Erika Dahl, Sara...</td>\n",
       "      <td>And we give You thanks for and ask Your protec...</td>\n",
       "      <td>Adoration and Lord's Prayer       .. 2 Chronic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-23</td>\n",
       "      <td>Chara Stevenson, Beth Pierce, Erika Dahl, Sara...</td>\n",
       "      <td>And we give You thanks for and ask Your protec...</td>\n",
       "      <td>Prayer of Adoration and Lord's Prayer        ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-30</td>\n",
       "      <td>Beth Pierce, Erika Dahl, Sarah Ann Haney, and ...</td>\n",
       "      <td>And we give You thanks for and ask Your protec...</td>\n",
       "      <td>Prayer of Adoration and Lord's Prayer Strasbou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-02-06</td>\n",
       "      <td>Beth Pierce, Erika Dahl, Sarah Ann Haney, and ...</td>\n",
       "      <td>And we give You thanks for and ask Your protec...</td>\n",
       "      <td>adoration Eternal and ever-blessed God, You ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-02-13</td>\n",
       "      <td>Beth Pierce, Erika Dahl, Sarah Ann Haney, and ...</td>\n",
       "      <td>And we give You thanks for and ask Your protec...</td>\n",
       "      <td>*Prayer of Adoration adoration Blessed art You...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2023-10-22</td>\n",
       "      <td>Sarah Mosley, Laura Dalton and Erika Dahl - to...</td>\n",
       "      <td>We give You thanks and ask Your protection for...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2023-10-29</td>\n",
       "      <td>Laura Dalton and Erika Dahl and Beth Pierce - ...</td>\n",
       "      <td>We give You thanks and ask Your protection for...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2023-11-05</td>\n",
       "      <td>Laura Dalton and Erika Dahl and Beth Pierce - ...</td>\n",
       "      <td>We give You thanks and ask Your protection for...</td>\n",
       "      <td>PRAYER OF ADORATION AND LORD'S PRAYER   . Lord...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2023-11-12</td>\n",
       "      <td>Laura Dalton and Erika Dahl and Beth Pierce - ...</td>\n",
       "      <td>We give You thanks and ask Your protection for...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2023-11-19</td>\n",
       "      <td>(Laura Dalton) and Erika Dahl and Beth Pierce ...</td>\n",
       "      <td>We give You thanks and ask Your protection for...</td>\n",
       "      <td>*Prayer of Adoration and Lord's Prayer Praise ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                   expectingMothers  \\\n",
       "0  2022-01-16  Chara Stevenson, Beth Pierce, Erika Dahl, Sara...   \n",
       "1  2022-01-23  Chara Stevenson, Beth Pierce, Erika Dahl, Sara...   \n",
       "2  2022-01-30  Beth Pierce, Erika Dahl, Sarah Ann Haney, and ...   \n",
       "3  2022-02-06  Beth Pierce, Erika Dahl, Sarah Ann Haney, and ...   \n",
       "4  2022-02-13  Beth Pierce, Erika Dahl, Sarah Ann Haney, and ...   \n",
       "..        ...                                                ...   \n",
       "92 2023-10-22  Sarah Mosley, Laura Dalton and Erika Dahl - to...   \n",
       "93 2023-10-29  Laura Dalton and Erika Dahl and Beth Pierce - ...   \n",
       "94 2023-11-05  Laura Dalton and Erika Dahl and Beth Pierce - ...   \n",
       "95 2023-11-12  Laura Dalton and Erika Dahl and Beth Pierce - ...   \n",
       "96 2023-11-19  (Laura Dalton) and Erika Dahl and Beth Pierce ...   \n",
       "\n",
       "                                  lineContainingQuery  \\\n",
       "0   And we give You thanks for and ask Your protec...   \n",
       "1   And we give You thanks for and ask Your protec...   \n",
       "2   And we give You thanks for and ask Your protec...   \n",
       "3   And we give You thanks for and ask Your protec...   \n",
       "4   And we give You thanks for and ask Your protec...   \n",
       "..                                                ...   \n",
       "92  We give You thanks and ask Your protection for...   \n",
       "93  We give You thanks and ask Your protection for...   \n",
       "94  We give You thanks and ask Your protection for...   \n",
       "95  We give You thanks and ask Your protection for...   \n",
       "96  We give You thanks and ask Your protection for...   \n",
       "\n",
       "                                   concatenatedValues  \n",
       "0   Adoration and Lord's Prayer       .. 2 Chronic...  \n",
       "1   Prayer of Adoration and Lord's Prayer        ....  \n",
       "2   Prayer of Adoration and Lord's Prayer Strasbou...  \n",
       "3   adoration Eternal and ever-blessed God, You ar...  \n",
       "4   *Prayer of Adoration adoration Blessed art You...  \n",
       "..                                                ...  \n",
       "92                                                     \n",
       "93                                                     \n",
       "94  PRAYER OF ADORATION AND LORD'S PRAYER   . Lord...  \n",
       "95                                                     \n",
       "96  *Prayer of Adoration and Lord's Prayer Praise ...  \n",
       "\n",
       "[97 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = DictionaryParser(data)\n",
    "\n",
    "em = parser.parse(\"next\", \"ask Your protection\", \"expectingMothers\")\n",
    "contains_query = parser.parse(\"contains\", \"ask Your protection\", \"lineContainingQuery\")\n",
    "between_query = parser.parse(\"between\", \"Adoration...Kedrov\", \"adoration\")\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "# List of DataFrames to merge\n",
    "dfs = [em, contains_query, between_query]\n",
    "\n",
    "# Merge all DataFrames on 'Date'\n",
    "final_merged_df = reduce(lambda left, right: pd.merge(left, right, on='Date', how='outer'), dfs)\n",
    "\n",
    "# Rename columns if needed\n",
    "final_merged_df.columns = ['Date', 'expectingMothers', 'lineContainingQuery', 'concatenatedValues']\n",
    "\n",
    "# Display the merged DataFrame\n",
    "final_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>adoration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-16</td>\n",
       "      <td>Adoration and Lord's Prayer       .. 2 Chronic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-23</td>\n",
       "      <td>Prayer of Adoration and Lord's Prayer        ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-30</td>\n",
       "      <td>Prayer of Adoration and Lord's Prayer Strasbou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-02-06</td>\n",
       "      <td>adoration Eternal and ever-blessed God, You ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-02-13</td>\n",
       "      <td>*Prayer of Adoration adoration Blessed art You...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2023-10-22</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2023-10-29</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2023-11-05</td>\n",
       "      <td>PRAYER OF ADORATION AND LORD'S PRAYER   . Lord...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2023-11-12</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2023-11-19</td>\n",
       "      <td>*Prayer of Adoration and Lord's Prayer Praise ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                          adoration\n",
       "0  2022-01-16  Adoration and Lord's Prayer       .. 2 Chronic...\n",
       "1  2022-01-23  Prayer of Adoration and Lord's Prayer        ....\n",
       "2  2022-01-30  Prayer of Adoration and Lord's Prayer Strasbou...\n",
       "3  2022-02-06  adoration Eternal and ever-blessed God, You ar...\n",
       "4  2022-02-13  *Prayer of Adoration adoration Blessed art You...\n",
       "..        ...                                                ...\n",
       "92 2023-10-22                                                   \n",
       "93 2023-10-29                                                   \n",
       "94 2023-11-05  PRAYER OF ADORATION AND LORD'S PRAYER   . Lord...\n",
       "95 2023-11-12                                                   \n",
       "96 2023-11-19  *Prayer of Adoration and Lord's Prayer Praise ...\n",
       "\n",
       "[97 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adoration = parser.parse(\"between\", \"adoration...Kedrov\", \"adoration\")\n",
    "adoration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>adoration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2022-04-24</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2022-05-01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2022-05-08</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2022-05-15</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2022-05-22</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2022-05-29</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2022-06-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2022-06-12</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2022-06-19</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2022-06-26</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2022-07-03</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2022-07-17</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2022-07-31</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2022-08-21</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2022-08-28</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2022-09-04</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2022-09-25</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2022-10-02</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2022-10-16</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2022-10-23</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2022-10-30</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2022-11-13</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2022-12-04</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2022-12-18</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2022-12-25</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2023-02-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2023-02-19</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2023-02-26</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2023-03-26</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2023-04-09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2023-04-16</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2023-04-23</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2023-04-30</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2023-05-07</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2023-05-14</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2023-05-21</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2023-05-28</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2023-06-04</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2023-06-11</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2023-06-18</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2023-06-25</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2023-07-09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2023-08-13</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2023-08-20</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2023-08-27</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2023-09-17</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2023-09-24</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2023-10-08</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2023-10-15</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2023-10-22</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2023-10-29</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2023-11-12</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date adoration\n",
       "14 2022-04-24          \n",
       "15 2022-05-01          \n",
       "16 2022-05-08          \n",
       "17 2022-05-15          \n",
       "18 2022-05-22          \n",
       "19 2022-05-29          \n",
       "20 2022-06-05          \n",
       "21 2022-06-12          \n",
       "22 2022-06-19          \n",
       "23 2022-06-26          \n",
       "24 2022-07-03          \n",
       "26 2022-07-17          \n",
       "28 2022-07-31          \n",
       "31 2022-08-21          \n",
       "32 2022-08-28          \n",
       "33 2022-09-04          \n",
       "36 2022-09-25          \n",
       "37 2022-10-02          \n",
       "39 2022-10-16          \n",
       "40 2022-10-23          \n",
       "41 2022-10-30          \n",
       "43 2022-11-13          \n",
       "46 2022-12-04          \n",
       "48 2022-12-18          \n",
       "49 2022-12-25          \n",
       "50 2023-01-01          \n",
       "55 2023-02-05          \n",
       "57 2023-02-19          \n",
       "58 2023-02-26          \n",
       "62 2023-03-26          \n",
       "64 2023-04-09          \n",
       "65 2023-04-16          \n",
       "66 2023-04-23          \n",
       "67 2023-04-30          \n",
       "68 2023-05-07          \n",
       "69 2023-05-14          \n",
       "70 2023-05-21          \n",
       "71 2023-05-28          \n",
       "72 2023-06-04          \n",
       "73 2023-06-11          \n",
       "74 2023-06-18          \n",
       "75 2023-06-25          \n",
       "77 2023-07-09          \n",
       "82 2023-08-13          \n",
       "83 2023-08-20          \n",
       "84 2023-08-27          \n",
       "87 2023-09-17          \n",
       "88 2023-09-24          \n",
       "90 2023-10-08          \n",
       "91 2023-10-15          \n",
       "92 2023-10-22          \n",
       "93 2023-10-29          \n",
       "95 2023-11-12          "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adoration[adoration['adoration'] == \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(adoration[adoration['adoration'] == \"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>expectingMothers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-16</td>\n",
       "      <td>Chara Stevenson, Beth Pierce, Erika Dahl, Sara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-23</td>\n",
       "      <td>Chara Stevenson, Beth Pierce, Erika Dahl, Sara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-30</td>\n",
       "      <td>Beth Pierce, Erika Dahl, Sarah Ann Haney, and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-02-06</td>\n",
       "      <td>Beth Pierce, Erika Dahl, Sarah Ann Haney, and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-02-13</td>\n",
       "      <td>Beth Pierce, Erika Dahl, Sarah Ann Haney, and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2023-10-22</td>\n",
       "      <td>Sarah Mosley, Laura Dalton and Erika Dahl - to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2023-10-29</td>\n",
       "      <td>Laura Dalton and Erika Dahl and Beth Pierce - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2023-11-05</td>\n",
       "      <td>Laura Dalton and Erika Dahl and Beth Pierce - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2023-11-12</td>\n",
       "      <td>Laura Dalton and Erika Dahl and Beth Pierce - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2023-11-19</td>\n",
       "      <td>(Laura Dalton) and Erika Dahl and Beth Pierce ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                   expectingMothers\n",
       "0  2022-01-16  Chara Stevenson, Beth Pierce, Erika Dahl, Sara...\n",
       "1  2022-01-23  Chara Stevenson, Beth Pierce, Erika Dahl, Sara...\n",
       "2  2022-01-30  Beth Pierce, Erika Dahl, Sarah Ann Haney, and ...\n",
       "3  2022-02-06  Beth Pierce, Erika Dahl, Sarah Ann Haney, and ...\n",
       "4  2022-02-13  Beth Pierce, Erika Dahl, Sarah Ann Haney, and ...\n",
       "..        ...                                                ...\n",
       "92 2023-10-22  Sarah Mosley, Laura Dalton and Erika Dahl - to...\n",
       "93 2023-10-29  Laura Dalton and Erika Dahl and Beth Pierce - ...\n",
       "94 2023-11-05  Laura Dalton and Erika Dahl and Beth Pierce - ...\n",
       "95 2023-11-12  Laura Dalton and Erika Dahl and Beth Pierce - ...\n",
       "96 2023-11-19  (Laura Dalton) and Erika Dahl and Beth Pierce ...\n",
       "\n",
       "[97 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Extract text\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mextract_text_between_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Convert the result to a DataFrame\u001b[39;00m\n\u001b[1;32m     35\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(result)\n",
      "Cell \u001b[0;32mIn[28], line 8\u001b[0m, in \u001b[0;36mextract_text_between_keys\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      5\u001b[0m result \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[43mentry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[1;32m      9\u001b[0m         start_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     10\u001b[0m         end_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def extract_text_between_keys(data):\n",
    "    result = []\n",
    "\n",
    "    for entry in data:\n",
    "        for key, value in entry.items():\n",
    "            start_key = None\n",
    "            end_key = None\n",
    "            collected_text = []\n",
    "\n",
    "            for line_key, line_value in value.items():\n",
    "                if \"Illumination\" in line_value:\n",
    "                    start_key = line_key\n",
    "                elif start_key and \" \" in line_value:\n",
    "                    end_key = line_key\n",
    "                    break\n",
    "                elif start_key:\n",
    "                    collected_text.append(line_value)\n",
    "\n",
    "            if start_key and end_key:\n",
    "                result.append({\"Date\": key, \"Illumination\": \" \".join(collected_text)})\n",
    "\n",
    "    return result\n",
    "\n",
    "# Read the JSON file\n",
    "with open('sorted_data.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract text\n",
    "result = extract_text_between_keys(data)\n",
    "\n",
    "# Convert the result to a DataFrame\n",
    "df = pd.DataFrame(result)\n",
    "\n",
    "# Display the DataFrame\n",
    "df\n",
    "# Optionally, save the DataFrame to a CSV file\n",
    "# df.to_csv('illumination_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 56\u001b[0m\n\u001b[1;32m     53\u001b[0m sundays_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sundays_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Ensure the Date column in the extracted DataFrame is of the same type\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Merge the DataFrames\u001b[39;00m\n\u001b[1;32m     59\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(sundays_df, df, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexes/range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Date'"
     ]
    }
   ],
   "source": [
    "with open('sorted_data.json', 'r') as file:\n",
    "    sorted_data = json.load(file)\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "\n",
    "def extract_text_between_keys(data):\n",
    "    result = []\n",
    "\n",
    "    for date, lines in data.items():\n",
    "        start_key = None\n",
    "        collected_text = []\n",
    "\n",
    "        for line_key, line_value in lines.items():\n",
    "            line_value_lower = line_value.lower()  # Convert text to lowercase for case-insensitive comparison\n",
    "\n",
    "            if \"ask Your protection\" in line_value_lower:\n",
    "                start_key = line_key\n",
    "            elif start_key and \" \" in line_value_lower:\n",
    "                break\n",
    "            elif start_key:\n",
    "                collected_text.append(line_value)\n",
    "\n",
    "        if start_key:\n",
    "            result.append({\"Date\": date, \"Illumination\": \" \".join(collected_text)})\n",
    "\n",
    "    return result\n",
    "\n",
    "def generate_sundays(start_date, end_date):\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        yield current_date\n",
    "        current_date += timedelta(days=7)\n",
    "\n",
    "# Assume sorted_data is already defined as a dictionary\n",
    "# sorted_data = ...\n",
    "\n",
    "# Extract text\n",
    "result = extract_text_between_keys(sorted_data)\n",
    "\n",
    "# Convert the result to a DataFrame\n",
    "df = pd.DataFrame(result)\n",
    "\n",
    "# Generate all Sundays between the specified dates\n",
    "start_date = datetime(2022, 1, 23)\n",
    "end_date = datetime(2023, 11, 19)\n",
    "sundays = list(generate_sundays(start_date, end_date))\n",
    "\n",
    "# Create a DataFrame with all Sundays and merge with the existing data\n",
    "sundays_df = pd.DataFrame(sundays, columns=[\"Date\"])\n",
    "sundays_df[\"Date\"] = sundays_df[\"Date\"].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Ensure the Date column in the extracted DataFrame is of the same type\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"]).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Merge the DataFrames\n",
    "merged_df = pd.merge(sundays_df, df, on=\"Date\", how=\"left\")\n",
    "\n",
    "# Fill NaN values in the Illumination column with blank strings\n",
    "merged_df[\"Illumination\"].fillna(\"\", inplace=True)\n",
    "\n",
    "\n",
    "def trim_after_amen(df, column_name):\n",
    "    # Define a case-insensitive regex pattern to find \"Amen.\" and trim text after it\n",
    "    pattern = re.compile(r'\\bAmen', re.IGNORECASE)\n",
    "\n",
    "    def trim_text(text):\n",
    "        # Search for the pattern and return text up to \"Amen.\"\n",
    "        match = pattern.search(text)\n",
    "        if match:\n",
    "            return text[:match.end()].strip()\n",
    "        return text.strip()\n",
    "\n",
    "    # Apply the trim_text function to the specified column\n",
    "    df[column_name] = df[column_name].apply(trim_text)\n",
    "\n",
    "# Assuming merged_df is already defined and contains the relevant data\n",
    "# merged_df = ...\n",
    "\n",
    "# Trim values in the 'Illumination' column\n",
    "trim_after_amen(merged_df, \"Illumination\")\n",
    "\n",
    "# Optionally, save the updated DataFrame to a CSV file\n",
    "# merged_df.to_csv('updated_illumination.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "# Save the DataFrame to a CSV file without the index\n",
    "merged_df.to_csv('illumination.csv', index=False)\n",
    "\n",
    "print(\"CSV file 'illumination.csv' has been created successfully.\")\n",
    "\n",
    "merged_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-16</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-23</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-30</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-02-06</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-02-13</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2023-10-22</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2023-10-29</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2023-11-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2023-11-12</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2023-11-19</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date EM\n",
       "0   2022-01-16   \n",
       "1   2022-01-23   \n",
       "2   2022-01-30   \n",
       "3   2022-02-06   \n",
       "4   2022-02-13   \n",
       "..         ... ..\n",
       "91  2023-10-22   \n",
       "92  2023-10-29   \n",
       "93  2023-11-05   \n",
       "94  2023-11-12   \n",
       "95  2023-11-19   \n",
       "\n",
       "[96 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Function to get the line after the line containing \"ask Your protection\"\n",
    "def get_em_line(lines_dict):\n",
    "    # Convert the dictionary to a list of keys\n",
    "    keys = list(lines_dict.keys())\n",
    "    values = list(lines_dict.values())\n",
    "    \n",
    "    # Iterate over the values to find the line containing \"ask Your protection\"\n",
    "    for i, value in enumerate(values):\n",
    "        if \"ask Your protection\" in value.lower():\n",
    "            # Check if the next line exists\n",
    "            if i + 1 < len(values):\n",
    "                return values[i + 1]  # Return the value of the next line\n",
    "            else:\n",
    "                return \"\"  # Return an empty string if no next line exists\n",
    "    return \"\"  # Return an empty string if \"ask Your protection\" is not found\n",
    "\n",
    "# Load your sorted_data.json\n",
    "with open('sorted_data.json', 'r') as file:\n",
    "    sorted_data = json.load(file)\n",
    "\n",
    "# Extract EM values from the sorted_data\n",
    "em_results = []\n",
    "for date, lines in sorted_data.items():\n",
    "    em_value = get_em_line(lines)\n",
    "    em_results.append({\"Date\": date, \"EM\": em_value})\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "em_df = pd.DataFrame(em_results)\n",
    "\n",
    "# Save the DataFrame to a CSV file without the index\n",
    "em_df.to_csv('em_values.csv', index=False)\n",
    "\n",
    "em_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y9/vqnw70t13k397rbgtnhky1_r0000gp/T/ipykernel_14194/2242990687.py:62: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"Illumination\"].fillna(\"\", inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Illumination</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-23</td>\n",
       "      <td>Prayer for Illumination [Bucer] Almighty, grac...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-30</td>\n",
       "      <td>Prayer for Illumination Strasbourg 1545 Our He...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-02-06</td>\n",
       "      <td>Prayer for Illumination Heidelberg Heavenly Fa...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-02-13</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-02-20</td>\n",
       "      <td>Prayer for Illumination Heavenly Father, Let Y...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2023-10-22</td>\n",
       "      <td>*PRAYER FOR ILLUMINATION          ..</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2023-10-29</td>\n",
       "      <td>Prayer for Illumination Now lead us, Gracious ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2023-11-05</td>\n",
       "      <td>*PRAYER FOR ILLUMINATION          .. Father, G...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2023-11-12</td>\n",
       "      <td>Let us Pray: Our Gracious Father in Heaven, gr...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2023-11-19</td>\n",
       "      <td>Prayer for Illumination                       ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date                                       Illumination EM\n",
       "0   2022-01-23  Prayer for Illumination [Bucer] Almighty, grac...   \n",
       "1   2022-01-30  Prayer for Illumination Strasbourg 1545 Our He...   \n",
       "2   2022-02-06  Prayer for Illumination Heidelberg Heavenly Fa...   \n",
       "3   2022-02-13                                                      \n",
       "4   2022-02-20  Prayer for Illumination Heavenly Father, Let Y...   \n",
       "..         ...                                                ... ..\n",
       "91  2023-10-22               *PRAYER FOR ILLUMINATION          ..   \n",
       "92  2023-10-29  Prayer for Illumination Now lead us, Gracious ...   \n",
       "93  2023-11-05  *PRAYER FOR ILLUMINATION          .. Father, G...   \n",
       "94  2023-11-12  Let us Pray: Our Gracious Father in Heaven, gr...   \n",
       "95  2023-11-19  Prayer for Illumination                       ...   \n",
       "\n",
       "[96 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('sorted_data.json', 'r') as file:\n",
    "    sorted_data = json.load(file)\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "\n",
    "def extract_text_between_keys(data):\n",
    "    result = []\n",
    "\n",
    "    for date, lines in data.items():\n",
    "        start_key = None\n",
    "        collected_text = []\n",
    "\n",
    "        for line_key, line_value in lines.items():\n",
    "            line_value_lower = line_value.lower()  # Convert text to lowercase for case-insensitive comparison\n",
    "\n",
    "            if \"world without end\" in line_value_lower:\n",
    "                start_key = line_key\n",
    "            elif start_key and \"seated\" in line_value_lower:\n",
    "                break\n",
    "            elif start_key:\n",
    "                collected_text.append(line_value)\n",
    "\n",
    "        if start_key:\n",
    "            result.append({\"Date\": date, \"Illumination\": \" \".join(collected_text)})\n",
    "\n",
    "    return result\n",
    "\n",
    "def generate_sundays(start_date, end_date):\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        yield current_date\n",
    "        current_date += timedelta(days=7)\n",
    "\n",
    "# Assume sorted_data is already defined as a dictionary\n",
    "# sorted_data = ...\n",
    "\n",
    "# Extract text\n",
    "result = extract_text_between_keys(sorted_data)\n",
    "\n",
    "# Convert the result to a DataFrame\n",
    "df = pd.DataFrame(result)\n",
    "\n",
    "# Generate all Sundays between the specified dates\n",
    "start_date = datetime(2022, 1, 23)\n",
    "end_date = datetime(2023, 11, 19)\n",
    "sundays = list(generate_sundays(start_date, end_date))\n",
    "\n",
    "# Create a DataFrame with all Sundays and merge with the existing data\n",
    "sundays_df = pd.DataFrame(sundays, columns=[\"Date\"])\n",
    "sundays_df[\"Date\"] = sundays_df[\"Date\"].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Ensure the Date column in the extracted DataFrame is of the same type\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"]).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Merge the DataFrames\n",
    "merged_df = pd.merge(sundays_df, df, on=\"Date\", how=\"left\")\n",
    "\n",
    "# Fill NaN values in the Illumination column with blank strings\n",
    "merged_df[\"Illumination\"].fillna(\"\", inplace=True)\n",
    "\n",
    "\n",
    "def trim_after_amen(df, column_name):\n",
    "    # Define a case-insensitive regex pattern to find \"Amen.\" and trim text after it\n",
    "    pattern = re.compile(r'\\bAmen', re.IGNORECASE)\n",
    "\n",
    "    def trim_text(text):\n",
    "        # Search for the pattern and return text up to \"Amen.\"\n",
    "        match = pattern.search(text)\n",
    "        if match:\n",
    "            return text[:match.end()].strip()\n",
    "        return text.strip()\n",
    "\n",
    "    # Apply the trim_text function to the specified column\n",
    "    df[column_name] = df[column_name].apply(trim_text)\n",
    "\n",
    "# Assuming merged_df is already defined and contains the relevant data\n",
    "# merged_df = ...\n",
    "\n",
    "# Trim values in the 'Illumination' column\n",
    "trim_after_amen(merged_df, \"Illumination\")\n",
    "\n",
    "# Extract the line after \"ask Your protection\"\n",
    "def get_em_line(data):\n",
    "    for line_key, line_value in data.items():\n",
    "        if \"ask Your protection\" in line_value.lower():\n",
    "            next_key = int(line_key.split()[-1]) + 1  # Assuming keys like \"Line 278\"\n",
    "            next_line_key = f\"Line {next_key}\"\n",
    "            return data.get(next_line_key, \"\")\n",
    "    return \"\"\n",
    "\n",
    "# Apply this extraction to create the EM column\n",
    "merged_df[\"EM\"] = merged_df[\"Date\"].apply(lambda date: get_em_line(sorted_data.get(date, {})))\n",
    "\n",
    "# Save the DataFrame to a CSV file without the index\n",
    "merged_df.to_csv('illumination.csv', index=False)\n",
    "\n",
    "merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate all Sundays within a range\n",
    "def generate_sundays(start_date, end_date):\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        yield current_date\n",
    "        current_date += timedelta(days=7)\n",
    "\n",
    "def read_docx(file_path):\n",
    "    doc = Document(file_path)\n",
    "    content = {}\n",
    "\n",
    "    for i, paragraph in enumerate(doc.paragraphs, start=1):\n",
    "        # Skip empty paragraphs\n",
    "        if paragraph.text.strip():\n",
    "            content[f'Line {i}'] = paragraph.text.strip()\n",
    "\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the range of dates\n",
    "start_date = datetime.strptime(\"2022-01-02\", \"%Y-%m-%d\")\n",
    "end_date = datetime.strptime(\"2023-11-19\", \"%Y-%m-%d\")\n",
    "\n",
    "# Get the list of existing files\n",
    "existing_files = sorted(Path(\"Worship Books\").rglob(\"*.docx\"))\n",
    "\n",
    "# Extract dates from the file names\n",
    "existing_dates = [datetime.strptime(file.stem, \"%Y-%m-%d\") for file in existing_files]\n",
    "\n",
    "# Check for missing dates\n",
    "missing_dates = [date.strftime(\"%Y-%m-%d\") for date in generate_sundays(start_date, end_date) if date not in existing_dates]\n",
    "\n",
    "# Print the missing dates\n",
    "if missing_dates:\n",
    "    print(\"Missing Dates:\")\n",
    "    for date in missing_dates:\n",
    "        print(date)\n",
    "else:\n",
    "    print(\"All dates are present.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jk = list(Path.cwd().rglob(\"*.docx\"))\n",
    "\n",
    "parsed_contents_dict = {}\n",
    "\n",
    "for file_path in jk:\n",
    "    parsed_contents = read_docx(file_path)\n",
    "\n",
    "    # Only add to the dictionary if there is content\n",
    "    if parsed_contents:\n",
    "        parsed_contents_dict[file_path.stem] = parsed_contents\n",
    "\n",
    "# Save to JSON file\n",
    "json_file_path = \"worshipbook.json\"\n",
    "with open(json_file_path, 'w') as json_file:\n",
    "    json.dump(parsed_contents_dict, json_file, indent=2)\n",
    "\n",
    "print(f\"Data saved to {json_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dict = {}\n",
    "\n",
    "for i in list(parsed_contents_dict.keys()):\n",
    "    first_lesson = ''\n",
    "    second_lesson = ''\n",
    "    gospel_lesson = ''\n",
    "    benediction = ''\n",
    "    entrance_psalm = ''\n",
    "    adoration_prayer = ''\n",
    "    absolution = ''\n",
    "    opening_call = ''\n",
    "\n",
    "    input_list = list(parsed_contents_dict[i].values())\n",
    "    \n",
    "    # Remove special characters and extra whitespaces\n",
    "    input_list = [re.sub(r'\\s+', ' ', item.replace('\\xa0', ' ').replace('\\t', ' ').strip()) for item in input_list]\n",
    "\n",
    "    # Extracting items between \"Adoration and L\" and \"Nikolai Kedrov\" for Prayer of Adoration\n",
    "    start_index = None\n",
    "    end_index = None\n",
    "\n",
    "    for idx, item in enumerate(input_list):\n",
    "        if \"Adoration and L\" in item:\n",
    "            start_index = idx + 1  # Start from the next item\n",
    "        elif \"Nikolai Kedrov\" in item:\n",
    "            end_index = idx\n",
    "            break  # Stop searching once you find the end\n",
    "        \n",
    "    if start_index is not None and end_index is not None:\n",
    "        result_list = input_list[start_index:end_index]\n",
    "        result_list = ' '.join(result_list)\n",
    "        result_list = result_list.rsplit(\"Now hear us as we sing the prayer our\", 1)[0].strip()\n",
    "        adoration_prayer = result_list.replace(\"  \", \" \")\n",
    "    else:\n",
    "        adoration_prayer = ''\n",
    "\n",
    "    # Extracting items between \"good news\" and \"Lift up your hearts\" for Absolution\n",
    "    start_index = None\n",
    "    end_index = None\n",
    "\n",
    "    for idx, item in enumerate(input_list):\n",
    "        if \"good news\" in item:\n",
    "            start_index = idx + 1  # Start from the next item\n",
    "        elif \"Lift up your hearts\" in item:\n",
    "            end_index = idx\n",
    "            break  # Stop searching once you find the end\n",
    "        \n",
    "    if start_index is not None and end_index is not None:\n",
    "        result_list = input_list[start_index:end_index]\n",
    "        result_list = ' '.join(result_list)\n",
    "        result_list = result_list.rsplit(\"Now hear us as we sing the prayer our\", 1)[0].strip()\n",
    "        absolution = result_list.replace(\"  \", \" \")\n",
    "    else:\n",
    "        absolution = ''\n",
    "\n",
    "    # Extracting \"Entrance Psalm\"\n",
    "    for j, k in enumerate(input_list):\n",
    "        cleaned_value = ' '.join(k.replace('\\t', ' ').split())\n",
    "\n",
    "        if \"Entrance Psalm\" in k:\n",
    "            entrance_psalm = cleaned_value.split(\"Entrance \", 1)[-1].strip()\n",
    "\n",
    "    # Extracting other lessons and benediction\n",
    "    for j, k in enumerate(input_list):\n",
    "        cleaned_value = ' '.join(k.replace('\\t', ' ').split())\n",
    "\n",
    "        if \"Second Lesson\" in k:\n",
    "            second_lesson = cleaned_value.split(\"Second Lesson\", 1)[-1].strip()\n",
    "        elif \"First Lesson\" in k:\n",
    "            first_lesson = cleaned_value.split(\"First Lesson\", 1)[-1].strip()\n",
    "        elif \"Gospel Lesson\" in k:\n",
    "            gospel_lesson = cleaned_value.split(\"Gospel Lesson\", 1)[-1].strip()\n",
    "        elif \"THE BENEDICTION\" in k:\n",
    "            benediction = cleaned_value.split(\"THE BENEDICTION\", 1)[-1].strip().replace(\"â€¦\", \"\").replace(\".\", \"\")\n",
    "        elif \"Psalm\" in k and opening_call == '' and j != 0:\n",
    "            opening_call = ' '.join(input_list[1:j]).strip()\n",
    "\n",
    "    # Add a dictionary for the date i with \"First Lesson\", \"Second Lesson\", and \"Gospel Lesson\" keys\n",
    "    test_dict[i] = {\n",
    "        \"Entrance Psalm\": entrance_psalm,\n",
    "        \"First Lesson\": first_lesson, \n",
    "        \"Second Lesson\": second_lesson, \n",
    "        \"Gospel Lesson\": gospel_lesson,\n",
    "        \"Benediction\": benediction,\n",
    "        \"Prayer of Adoration\": adoration_prayer,\n",
    "        \"Absolution\": absolution,\n",
    "        \"Opening Call\": opening_call\n",
    "    }\n",
    "\n",
    "\n",
    "test_dict['2022-05-01']['Absolution'] = \"We extol You, Lord, for lifting us up above the rejoicing of our enemies â€“ for bringing us healing by the wounds of our Lord Jesus â€“ and bringing up our souls from the grave by His rising again to new life â€“ the precious guarantee to us that our weeping in the night will give way to joy in the morning. Gracious God, we will give thanks to You forever.\"\n",
    "\n",
    "#test_dict['2023-08-20']['Absolution'] = \n",
    "#test_dict['2023-06-04']['Absolution'] = \n",
    "#test_dict['2023-04-23']['Absolution'] = \n",
    "#test_dict['2022-08-28']['Absolution'] = \n",
    "#test_dict['2022-06-12']['Absolution'] = \n",
    "\n",
    "test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find keys where Absolution is blank\n",
    "keys_with_blank_absolution = [key for key, value in test_dict.items() if value.get('Absolution') == '']\n",
    "\n",
    "print(keys_with_blank_absolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming test_dict is your dictionary\n",
    "data = []\n",
    "\n",
    "for date, lessons in test_dict.items():\n",
    "    row = {'Date': date}\n",
    "    row.update(lessons)\n",
    "    data.append(row)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df.sort_values(by='Date', ascending=False)\n",
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"worshipbook.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Create a boolean DataFrame where True represents a blank cell\n",
    "blank_matrix = df.applymap(lambda x: x == '')\n",
    "\n",
    "# Plotting the heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(blank_matrix, cmap='viridis', aspect='auto')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xticks(range(len(df.columns)), df.columns)\n",
    "plt.yticks(range(len(df)), df['Date'].dt.strftime('%Y-%m-%d'))\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Rows')\n",
    "plt.title('Blank Values Heatmap')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_matrix = df.applymap(lambda x: x == '')\n",
    "\n",
    "# Calculate percentage of missing values for each column\n",
    "percentage_missing = (missing_matrix.sum() / len(missing_matrix)) * 100\n",
    "\n",
    "percentage_missing = percentage_missing.to_frame().reset_index()\n",
    "percentage_missing.columns = ['Features', 'Percent Missing']\n",
    "\n",
    "percentage_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = pd.read_excel(, header=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_headers = {\n",
    "    'Column1': 'Date',\n",
    "    'Column2': 'Type',\n",
    "    'Column3': 'Title',\n",
    "    'Column4': 'Time',\n",
    "\n",
    "    # Add more column mappings as needed\n",
    "}\n",
    "\n",
    "# Read the Excel file with custom headers\n",
    "songs = pd.read_excel(\"Song_List.xlsx\", names=custom_headers.values())\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "# Create a new row as a dictionary\n",
    "new_row = {\n",
    "    'Date': '2021-01-03',\n",
    "    'Type': 'Entrance Hymn',\n",
    "    'Title': 'Unto Me the Word Remember',\n",
    "    'Time': 'Christmas'\n",
    "}\n",
    "\n",
    "\t\t\t\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "new_row_df = pd.DataFrame([new_row])\n",
    "\n",
    "# Concatenate the new row DataFrame with the original DataFrame, placing the new row at the top\n",
    "songs = pd.concat([new_row_df, songs]).reset_index(drop=True)\n",
    "\n",
    "songs['Date'] = pd.to_datetime(songs['Date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "# Display the DataFrame with the new row at the top\n",
    "songs.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_of_year = songs[['Date', 'Time']]\n",
    "time_of_year['Date'] = pd.to_datetime(time_of_year['Date'])\n",
    "# Assuming time_of_year is your DataFrame containing 'Date' and 'Time' columns\n",
    "# Drop duplicate rows\n",
    "time_of_year = time_of_year.drop_duplicates()\n",
    "time_of_year = time_of_year.reset_index(drop=True)\n",
    "\n",
    "# Display the DataFrame\n",
    "time_of_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs.Type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the DataFrame\n",
    "df_pivot = songs.pivot_table(index='Date', columns='Type', values='Title', aggfunc=lambda x: ' '.join(x))\n",
    "\n",
    "# Reset index to make 'Date' a column again\n",
    "df_pivot.reset_index(inplace=True)\n",
    "\n",
    "# Remove the index name\n",
    "df_pivot.index.name = None\n",
    "\n",
    "# Reset the name of the columns index to None\n",
    "df_pivot.columns.name = None\n",
    "\n",
    "# Reorder the columns as specified\n",
    "df_pivot = df_pivot[['Date', 'Entrance Hymn', 'Epistle Hymn', 'Offertory', 'Bread', 'Cup', 'Hymn of Response']]\n",
    "\n",
    "df_pivot['Date'] = pd.to_datetime(df_pivot['Date'])\n",
    "\n",
    "# Display the transformed DataFrame\n",
    "df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "# Create a boolean DataFrame indicating NaN values\n",
    "nan_map = df_pivot.isna()\n",
    "\n",
    "# Visualize the NaN map\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(nan_map, cmap='viridis', cbar=False)\n",
    "plt.title('NaN Map in DataFrame')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Rows')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_pivot is your pivot DataFrame and you have another DataFrame named 'other_df' to merge with\n",
    "# Merge the DataFrames on the 'Date' column\n",
    "merged_df = pd.merge(df_pivot, df, on='Date', how='inner')\n",
    "merged_df = pd.merge(merged_df, time_of_year, on='Date', how='inner')\n",
    "\n",
    "# Display the merged DataFrame\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Add blank columns to the merged DataFrame\n",
    "merged_df['Entrance Call to Worship Prelude'] = np.nan\n",
    "merged_df['Entrance Call to Worship'] = np.nan\n",
    "merged_df['Confession of Sins Prelude'] = np.nan\n",
    "merged_df['Confession of Sins'] = np.nan\n",
    "merged_df['Assurance of Forgiveness Prelude'] = np.nan\n",
    "merged_df['Absolution'] = np.nan\n",
    "merged_df['Prayer for Illumination'] = np.nan\n",
    "merged_df['Presentation of Tithes and Offerings Passage Prelude'] = np.nan\n",
    "merged_df['Presentation of Tithes and Offerings'] = np.nan\n",
    "merged_df['Prayer for the Church and the World Prelude'] = np.nan\n",
    "merged_df['Prayer for the Church and the World Local Church'] = np.nan\n",
    "merged_df['Prayer for the Church and the World MOW'] = np.nan\n",
    "merged_df['Prayer for the Church and the World Persecuted Saints'] = np.nan\n",
    "merged_df['Prayer for the Church and the World Suffering Saints'] = np.nan\n",
    "merged_df['Prayer for the Church and the World Expecting Mothers'] = np.nan\n",
    "merged_df['Prayer for the Church and the World Culture and Nation'] = np.nan\n",
    "merged_df['Prayer for the Church and the World Epilogue'] = np.nan\n",
    "merged_df['Prayer Giving Thanks for the Bread'] = np.nan\n",
    "merged_df['Prayer Giving Thanks for the Cup'] = np.nan\n",
    "merged_df['The Great Commission'] = np.nan\n",
    "# Add more blank columns as needed\n",
    "\n",
    "service_order = [\n",
    "    \"Date\",\n",
    "    'Time',\n",
    "    'Entrance Call to Worship Prelude',\n",
    "    'Entrance Call to Worship',\n",
    "    'Entrance Hymn',\n",
    "    'Entrance Psalm',\n",
    "    'Prayer of Adoration',\n",
    "    'Confession of Sins Prelude',\n",
    "    'Confession of Sins',\n",
    "    'Assurance of Forgiveness Prelude',\n",
    "    'Absolution',\n",
    "    'First Lesson',\n",
    "    'Second Lesson',\n",
    "    'Epistle Hymn',\n",
    "    'Gospel Lesson',\n",
    "    'Prayer for Illumination',\n",
    "    'Offertory',\n",
    "    'Presentation of Tithes and Offerings Passage Prelude',\n",
    "    'Presentation of Tithes and Offerings',\n",
    "    'Prayer for the Church and the World Prelude',\n",
    "    'Prayer for the Church and the World Local Church',\n",
    "    'Prayer for the Church and the World MOW',\n",
    "    'Prayer for the Church and the World Persecuted Saints',\n",
    "    'Prayer for the Church and the World Suffering Saints',\n",
    "    'Prayer for the Church and the World Expecting Mothers',\n",
    "    'Prayer for the Church and the World Culture and Nation',\n",
    "    'Prayer for the Church and the World Epilogue',\n",
    "    'Prayer Giving Thanks for the Bread',\n",
    "    'Bread',\n",
    "    'Prayer Giving Thanks for the Cup',\n",
    "    'Cup',\n",
    "    'The Great Commission',\n",
    "    'Benediction',\n",
    "    'Hymn of Response'\n",
    "]\n",
    "\n",
    "# Reorder the columns\n",
    "merged_df = merged_df[service_order]\n",
    "\n",
    "# Display the DataFrame with added blank columns and reordered columns\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Replace empty strings with NaN values\n",
    "merged_df.replace('', np.nan, inplace=True)\n",
    "\n",
    "# Create NaN map\n",
    "nan_map = merged_df.isna()\n",
    "\n",
    "# Visualize the NaN map\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(nan_map, cmap='viridis', cbar=False)\n",
    "plt.title('NaN Map in DataFrame')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Rows')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming merged_df is your DataFrame containing 'Date' and 'Time' columns\n",
    "\n",
    "# Initialize variables\n",
    "current_value = merged_df['Time'].iloc[0]\n",
    "count = 1\n",
    "\n",
    "# Iterate over the 'Time' column\n",
    "for i in range(1, len(merged_df)):\n",
    "    if merged_df['Time'].iloc[i] == current_value:\n",
    "        count += 1\n",
    "        merged_df.at[i, 'Time'] = f\"{count}{'th' if count > 3 else ['st', 'nd', 'rd'][count - 1]} Sunday in {current_value}\"\n",
    "    else:\n",
    "        current_value = merged_df['Time'].iloc[i]\n",
    "        count = 1\n",
    "\n",
    "# Display the updated DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"best_book_yet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Read the JSON file\n",
    "with open('worshipbook.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Sort the JSON data by key in ascending order\n",
    "sorted_data = dict(sorted(data.items()))\n",
    "\n",
    "# Display the sorted data\n",
    "print(sorted_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Assuming sorted_data is your sorted dictionary\n",
    "# Define the file path to save the JSON file\n",
    "file_path = 'sorted_data.json'\n",
    "\n",
    "# Save the sorted dictionary to a JSON file\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(sorted_data, file, indent=4)\n",
    "\n",
    "print(f\"Sorted data has been saved to '{file_path}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Open the JSON file and load it as song_dict\n",
    "with open('sorted_data.json', 'r') as file:\n",
    "    song_dict = json.load(file)\n",
    "\n",
    "# Initialize an empty list to store the filtered data\n",
    "filtered_data = []\n",
    "\n",
    "# Iterate over the items in song_dict\n",
    "for date, values in song_dict.items():\n",
    "    for line, value in values.items():\n",
    "        if \"GREAT COMMISSION\" in value:\n",
    "            filtered_data.append({'Date': date, 'Value': value})\n",
    "            break  # Stop searching for \"GREAT COMMISSION\" in this date entry once found\n",
    "\n",
    "# Convert the filtered data list into a pandas DataFrame\n",
    "df = pd.DataFrame(filtered_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Bible references using regular expressions\n",
    "df['Bible_Reference'] = df['Value'].str.extract(r'\\b([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)?\\s+\\d+:\\d+(?:-\\d+)?)(?!\\S)')\n",
    "\n",
    "# Display the DataFrame with cleaned-up values\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Date' column to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Find the first and last Sundays in the 'Date' column\n",
    "first_sunday = df['Date'].min() - pd.Timedelta(days=df['Date'].min().weekday())  # Go back to the previous Sunday\n",
    "last_sunday = df['Date'].max() + pd.Timedelta(days=6 - df['Date'].max().weekday())  # Go forward to the next Sunday\n",
    "\n",
    "# Generate a range of all Sundays between the first and last Sundays\n",
    "all_sundays = pd.date_range(start=first_sunday, end=last_sunday, freq='W-SUN')\n",
    "\n",
    "# Create a DataFrame with the Sundays in the range\n",
    "sundays_df = pd.DataFrame({'Date': all_sundays})\n",
    "\n",
    "# Merge the original DataFrame with the Sundays DataFrame to fill in missing Sundays\n",
    "merged_df = pd.merge(sundays_df, df, on='Date', how='left')\n",
    "\n",
    "# Display the merged DataFrame\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"commissions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Open the JSON file and load its contents into a nested dictionary\n",
    "with open('sorted_data.json', 'r') as file:\n",
    "    nested_dict = json.load(file)\n",
    "\n",
    "# Initialize lists to store the extracted data\n",
    "dates = []\n",
    "values = []\n",
    "\n",
    "# Iterate over the items in nested_dict\n",
    "for date, values_dict in nested_dict.items():\n",
    "    # Check if \"Presentation of Tithes and Offering\" is in the values\n",
    "    if \"Presentation of Tithes and Offering\" in values_dict.values():\n",
    "        # Find the next value after \"Presentation of Tithes and Offering\"\n",
    "        next_value = None\n",
    "        for key, value in values_dict.items():\n",
    "            if next_value is not None:\n",
    "                break\n",
    "            if value == \"Presentation of Tithes and Offering\":\n",
    "                next_value = values_dict.get(list(values_dict)[list(values_dict).index(key) + 1], None)\n",
    "        \n",
    "        # Append the date and value to the lists\n",
    "        dates.append(date)\n",
    "        values.append(next_value)\n",
    "\n",
    "# Create a DataFrame\n",
    "offertory_df = pd.DataFrame({'Date': dates, 'Value': values})\n",
    "offertory_df['Date'] = pd.to_datetime(offertory_df['Date'])\n",
    "\n",
    "# Display the DataFrame\n",
    "offertory_df\n",
    "\n",
    "# Create a DataFrame with all Sundays between '2022-01-02' and '2023-11-19'\n",
    "all_sundays = pd.date_range(start='2022-01-02', end='2023-11-19', freq='W-SUN')\n",
    "sundays_df = pd.DataFrame({'Date': all_sundays})\n",
    "\n",
    "# Merge the existing data with the DataFrame containing all Sundays\n",
    "merged_df = pd.merge(sundays_df, offertory_df, on='Date', how='left')\n",
    "\n",
    "# Display the merged DataFrame\n",
    "merged_df\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Assuming merged_df is your DataFrame containing the data\n",
    "\n",
    "# Define a function to extract Bible references from the \"Value\" column\n",
    "def extract_bible_reference(value):\n",
    "    if isinstance(value, str):\n",
    "        # Regular expression pattern to match Bible references\n",
    "        pattern = r'([A-Z][A-Z]+(?:\\s+\\d+:\\d+(?:-\\d+)?)?)'\n",
    "        # Search for matches in the value\n",
    "        matches = re.findall(pattern, value)\n",
    "        # Join the matches into a single string, if any\n",
    "        return ', '.join(matches) if matches else None\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Apply the function to extract Bible references and create the \"Reference\" column\n",
    "merged_df['Reference'] = merged_df['Value'].apply(extract_bible_reference)\n",
    "\n",
    "# Display the DataFrame with the extracted references\n",
    "merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Open the JSON file and load its contents into a nested dictionary\n",
    "with open('sorted_data.json', 'r') as file:\n",
    "    nested_dict = json.load(file)\n",
    "\n",
    "# Initialize lists to store the extracted data\n",
    "dates = []\n",
    "values = []\n",
    "\n",
    "# Iterate over the items in nested_dict\n",
    "for date, values_dict in nested_dict.items():\n",
    "    # Check if \"Presentation of Tithes and Offering\" is in the values\n",
    "    if \"Nicene Creed\" in values_dict.values():\n",
    "        # Find the next value after \"Presentation of Tithes and Offering\"\n",
    "        next_value = None\n",
    "        for key, value in values_dict.items():\n",
    "            if next_value is not None:\n",
    "                break\n",
    "            if value == \"Nicene Creed\":\n",
    "                next_value = values_dict.get(list(values_dict)[list(values_dict).index(key) - 1], None)\n",
    "        \n",
    "        # Append the date and value to the lists\n",
    "        dates.append(date)\n",
    "        values.append(next_value)\n",
    "\n",
    "# Create a DataFrame\n",
    "offertory_df = pd.DataFrame({'Date': dates, 'Value': values})\n",
    "offertory_df['Date'] = pd.to_datetime(offertory_df['Date'])\n",
    "\n",
    "# Display the DataFrame\n",
    "offertory_df\n",
    "\n",
    "# Create a DataFrame with all Sundays between '2022-01-02' and '2023-11-19'\n",
    "all_sundays = pd.date_range(start='2022-01-02', end='2023-11-19', freq='W-SUN')\n",
    "sundays_df = pd.DataFrame({'Date': all_sundays})\n",
    "\n",
    "# Merge the existing data with the DataFrame containing all Sundays\n",
    "merged_df = pd.merge(sundays_df, offertory_df, on='Date', how='left')\n",
    "\n",
    "\n",
    "\n",
    "# Display the DataFrame with the extracted references\n",
    "merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"prayer_world_epilogue.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load the nested dictionary from the JSON file\n",
    "with open('sorted_data.json', 'r') as file:\n",
    "    nested_dict = json.load(file)\n",
    "\n",
    "# Function to find the closest value containing \"For You are gracious\"\n",
    "def find_closest_gracious_value(values_dict):\n",
    "    try:\n",
    "        nicene_creed_index = list(values_dict.values()).index(\"Nicene Creed\")\n",
    "    except ValueError:\n",
    "        return None\n",
    "    \n",
    "    for key, value in list(values_dict.items())[nicene_creed_index:]:\n",
    "        if \"For You are gracious\" in value:\n",
    "            return value\n",
    "\n",
    "# Initialize lists to store the extracted data\n",
    "dates = []\n",
    "combined_values = []\n",
    "\n",
    "# Iterate over the items in the nested dictionary\n",
    "for date, values_dict in nested_dict.items():\n",
    "    # Find the closest value containing \"For You are gracious\"\n",
    "    closest_gracious_value = find_closest_gracious_value(values_dict)\n",
    "    \n",
    "    # If a closest value is found, extract values between \"Nicene Creed\" and the closest gracious value\n",
    "    if closest_gracious_value:\n",
    "        nicene_creed_index = list(values_dict.values()).index(\"Nicene Creed\")\n",
    "        closest_gracious_index = list(values_dict.values()).index(closest_gracious_value)\n",
    "        combined_values.append(\" \".join(list(values_dict.values())[nicene_creed_index + 1:closest_gracious_index]))\n",
    "    else:\n",
    "        combined_values.append(None)\n",
    "    \n",
    "    dates.append(date)\n",
    "\n",
    "# Create a DataFrame\n",
    "combined_values_df = pd.DataFrame({'Date': dates, 'Combined_Values': combined_values})\n",
    "combined_values_df['Date'] = pd.to_datetime(combined_values_df['Date'])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(combined_values_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read CSV file into DataFrame\n",
    "df = pd.read_csv('New Worship Book Responses.csv')\n",
    "\n",
    "# Convert DataFrame to JSON\n",
    "json_data = df.to_json(orient='records')\n",
    "\n",
    "# Print or save the JSON data\n",
    "print(json_data)\n",
    "\n",
    "# If you want to save the JSON data to a file\n",
    "with open('Responses-test.json', 'w') as f:\n",
    "    f.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "\n",
    "# Load JSON data\n",
    "data = json.loads(json_data)\n",
    "\n",
    "# Create HTML table string\n",
    "html_table = '<table border=\"1\">'\n",
    "html_table += '<tr>'\n",
    "for key in data[0].keys():\n",
    "    html_table += '<th>{}</th>'.format(key)\n",
    "html_table += '</tr>'\n",
    "for row in data:\n",
    "    html_table += '<tr>'\n",
    "    for value in row.values():\n",
    "        html_table += '<td height=\"50\">{}</td>'.format(value)\n",
    "    html_table += '</tr>'\n",
    "html_table += '</table>'\n",
    "\n",
    "# Display or save the HTML table\n",
    "print(html_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to save the HTML table to a file\n",
    "with open('table.html', 'w') as f:\n",
    "    f.write(html_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
